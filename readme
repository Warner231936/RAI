base directory

Discord KoboldCPP Bot
---------------------
This repo includes a Python Discord bot that connects to a local KoboldCPP instance
running the Qwen2.5-14B-Instruct-Q5_K_M.gguf model on CUDA. The bot loads shared
memory from `kobold_discord_bot/memory.md` and stores per-user conversation
history in `kobold_discord_bot/user_memory.json`. The same storage is used by a
simple web interface so multiple users can chat with Requiem concurrently.

Usage:
1. Install dependencies: `pip install -r kobold_discord_bot/requirements.txt`.
2. Start the model servers: `python kobold_discord_bot/launch_kobold.py`.
   - `MAIN_MODEL` / `KOBOLD_PORT` control the primary model.
   - Set `ASSIST_MODEL` / `ASSIST_PORT` to launch an optional helper model.
3. Set environment variable `DISCORD_TOKEN` with your bot token.
4. Optionally set `KOBOLD_ASSIST_URL` to point to the helper model endpoint.
5. Run the Discord bot: `python kobold_discord_bot/bot.py`.
6. To chat in a browser, run the web app: `python kobold_discord_bot/web_ui.py`
   and visit `http://localhost:8080`.

Commands:
- `!forget` – clear your saved conversation history.
- `!reload` – reload the shared memory file (admin only).
- `!emotion <mood>` – set or view your preferred emotional tone.
- `!help` – list available commands.

### Optional assistant model
Set `KOBOLD_ASSIST_URL` to point to a second, smaller KoboldCPP model. The bot will
query this model for short emotional hints to feed into the main model, giving the
Requiem persona more expressive variance in its replies.
