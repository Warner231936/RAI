base directory

Discord KoboldCPP Bot
---------------------
This repo includes a Python Discord bot that connects to a local KoboldCPP instance
running the Qwen2.5-14B-Instruct-Q5_K_M.gguf model on CUDA. The bot loads shared
memory from `kobold_discord_bot/memory.md` and stores per-user conversation
history in `kobold_discord_bot/user_memory.json`. The same storage is used by a
simple web interface so multiple users can chat with Requiem concurrently.

A lightweight Galaxy Online 2 knowledge base lives in `kobold_discord_bot/go2_data.json`.
Requiem automatically searches this file for relevant facts when building a
response, letting her answer lore and mechanics questions without extra setup.
Expand the JSON with your own data to teach her more about the game.

Usage:
1. Install dependencies: `pip install -r kobold_discord_bot/requirements.txt`.
2. Start the model servers: `python kobold_discord_bot/launch_kobold.py`.
   - `MAIN_MODEL` / `KOBOLD_PORT` control the primary 14B model.
   - `INTENT_MODEL` / `INTENT_PORT` launch a small (≈4B) classifier.
   - `THOUGHTS_MODEL` / `THOUGHTS_PORT` launch a mid (≈7B) planner.
3. Set environment variable `DISCORD_TOKEN` with your bot token.
4. Optionally tune concurrency with `MAX_WORKERS` (default 4). This limits the
   number of simultaneous generation/image requests and helps prevent crashes
   under heavy load. Requests will automatically retry on transient HTTP errors.
5. Run the Discord bot: `python kobold_discord_bot/bot.py`.
6. To chat in a browser, run the web app: `python kobold_discord_bot/web_ui.py`
   and visit `http://localhost:8080`.
7. Messages are auto-translated to English for processing and translated back
   to the user's language for the final reply, enabling multilingual chats.
8. A background memory manager periodically summarizes older dialogue to keep
   per-user histories short and reduce load.
   
Commands:
- `!helpme` – list available commands.
- `!forget` – clear your saved conversation history.
- `!reload` – reload the shared memory file (admin only).
- `!emotion <mood>` – set or view your preferred emotional tone.
- `!img <prompt>` – generate an image via AUTOMATIC1111 and post it.
- `!go2 <text>` – lookup Galaxy Online 2 information from the built-in database.
- `!memoryfile` / `!memoryhere` – DM or post the exported memory file.
- `!anchors` – show top anchors from the exported memory file.
- `!memfind <text>` – search the exported memory file for text.

The web interface also exposes an **Image** button for quick text-to-image
generation.

### Optional assistant model
The bot now uses a four-stage orchestrator:

1. **Intent** – a tiny model classifies the user's request.
2. **Thoughts** – a mid model plans the steps and tone.
3. **Emotion** – the intent model emits a brief tone hint.
4. **Core** – the 14B model generates the final reply.

The orchestrator also runs a coherence check with the intent model before
delivering the answer, retrying once if the response doesn't address the user
message.

Provide URLs for the three models via `INTENT_URL`, `THOUGHTS_URL` and
`KOBOLD_URL` if you run them separately. The helper models keep Requiem
responsive while supporting multiple simultaneous users.

### Performance tuning
Environment variables:

- `MAX_WORKERS` – max concurrent requests handled by the bot and web UI.
- `HTTP_TIMEOUT` – seconds to wait for model/image servers before giving up.
