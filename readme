base directory

Discord KoboldCPP Bot
---------------------
This repo includes a Python Discord bot that connects to a local KoboldCPP instance
running the Qwen2.5-14B-Instruct-Q5_K_M.gguf model on CUDA. The bot loads shared
memory from `kobold_discord_bot/memory.md` and stores per-user conversation
history in `kobold_discord_bot/user_memory.json`. The same storage is used by a
simple web interface so multiple users can chat with Requiem concurrently.

Usage:
1. Install dependencies: `pip install -r kobold_discord_bot/requirements.txt`.
2. Start the model servers: `python kobold_discord_bot/launch_kobold.py`.
   - `MAIN_MODEL` / `KOBOLD_PORT` control the primary model.
   - Set `ASSIST_MODEL` / `ASSIST_PORT` to launch an optional helper model.
3. Set environment variable `DISCORD_TOKEN` with your bot token.
4. Optionally set `KOBOLD_ASSIST_URL` to point to the helper model endpoint.
5. Optionally tune concurrency with `MAX_WORKERS` (default 4). This limits the
   number of simultaneous generation/image requests and helps prevent crashes
   under heavy load. Requests will automatically retry on transient HTTP errors.
6. Run the Discord bot: `python kobold_discord_bot/bot.py`.
7. To chat in a browser, run the web app: `python kobold_discord_bot/web_ui.py`
   and visit `http://localhost:8080`.

Commands:
- `!helpme` – list available commands.
- `!forget` – clear your saved conversation history.
- `!reload` – reload the shared memory file (admin only).
- `!emotion <mood>` – set or view your preferred emotional tone.
- `!img <prompt>` – generate an image via AUTOMATIC1111 and post it.
- `!memoryfile` / `!memoryhere` – DM or post the exported memory file.
- `!anchors` – show top anchors from the exported memory file.
- `!memfind <text>` – search the exported memory file for text.

### Optional assistant model
Set `KOBOLD_ASSIST_URL` to point to a second, smaller KoboldCPP model. The bot will
query this model for short emotional hints to feed into the main model, giving the
Requiem persona more expressive variance in its replies.

### Performance tuning
Environment variables:

- `MAX_WORKERS` – max concurrent requests handled by the bot and web UI.
- `HTTP_TIMEOUT` – seconds to wait for model/image servers before giving up.
